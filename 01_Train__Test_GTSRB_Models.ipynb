{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yIoyKemTUc45"
   },
   "source": [
    "### **Train and Test the Models on the GTSRB dataset**\n",
    "\n",
    "Three models for traffic sign classification:\n",
    "1. CNNsmall (original LISA-CNN)\n",
    "2. CNNlarge (original GTSRB-CNN)\n",
    "3. CNN-STN \n",
    "\n",
    "Five generic image classification models\n",
    "1. ResNet18\n",
    "2. EfficientNet-B0\n",
    "3. DenseNet-121\n",
    "4. MobileNetv2\n",
    "5. ShuffleNetv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3476,
     "status": "ok",
     "timestamp": 1688977143403,
     "user": {
      "displayName": "Leopold Müller",
      "userId": "15867647540029964791"
     },
     "user_tz": -120
    },
    "id": "65VAjUnH2gSO",
    "outputId": "ad5c3dfa-da68-4d00-fa66-ee228015d693"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: 39209 which is 75.64% of the total dataset\n",
      "Test data size: 12630 which is 24.36% of the total dataset\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('dataset/GTSRB/train.pkl', 'rb') as f:\n",
    "    train = pickle.load(f)\n",
    "    train_data, train_labels = train['data'], train['labels']\n",
    "with open('dataset/GTSRB/test.pkl', 'rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    test_data, test_labels = test['data'], test['labels']\n",
    "\n",
    "# Calculate the sizes in percentage\n",
    "total_size = len(train_data) + len(test_data)\n",
    "train_percentage = (len(train_data) / total_size) * 100\n",
    "test_percentage = (len(test_data) / total_size) * 100\n",
    "\n",
    "print(f\"Training data size: {len(train_data)} which is {train_percentage:.2f}% of the total dataset\")\n",
    "print(f\"Test data size: {len(test_data)} which is {test_percentage:.2f}% of the total dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "BAQRIesHUc5D"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import json\n",
    "from models import *\n",
    "from utils import *\n",
    "from torchvision.models import mobilenet_v2, efficientnet_b0, densenet121, shufflenet_v2_x1_0\n",
    "\n",
    "# gtsrb dataset\n",
    "with open('classes.json', 'r') as config:\n",
    "    params = json.load(config)\n",
    "    class_n = params['GTSRB']['class_n']\n",
    "    device = params['device']\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model_name, adv_train=False):\n",
    "\n",
    "    with open('dataset/GTSRB/train.pkl', 'rb') as f:\n",
    "        train = pickle.load(f)\n",
    "        train_data, train_labels = train['data'], train['labels']\n",
    "    with open('dataset/GTSRB/test.pkl', 'rb') as f:\n",
    "        test = pickle.load(f)\n",
    "        test_data, test_labels = test['data'], test['labels']\n",
    "\n",
    "    print('Loading .pkl done.')\n",
    "\n",
    "    processed_train = np.array([\n",
    "        pre_process_image(train_data[i]) for i in range(len(train_data))],\n",
    "        dtype=np.float32) if not adv_train else train_data\n",
    "\n",
    "    print('Processing train data done.')\n",
    "\n",
    "    processed_test = np.array([\n",
    "        pre_process_image(test_data[i]) for i in range(len(test_data))],\n",
    "        dtype=np.float32)\n",
    "\n",
    "    print('Processing test data done.')\n",
    "\n",
    "    augment_data_train, augment_data_labels = gen_extra_data(\n",
    "        train_data, train_labels, 10, 30, 5, 5, 1, preprocess=not adv_train)\n",
    "\n",
    "    print('Augmentation process done.')\n",
    "\n",
    "    image_train = np.concatenate([processed_train, augment_data_train], 0)\n",
    "    label_train = np.concatenate([train_labels, augment_data_labels], 0)\n",
    "    image_test, label_test = processed_test, test_labels\n",
    "\n",
    "    if model_name=='TransformerGTSRB':\n",
    "        training_model = Transformer(class_n=class_n).to(device).apply(weights_init)\n",
    "    elif model_name=='CNNsmallGTSRB':\n",
    "        training_model = CNNsmall(class_n=class_n).to(device).apply(weights_init)\n",
    "    elif model_name=='CNNlargeGTSRB':\n",
    "        training_model = CNNlarge(class_n=class_n).to(device).apply(weights_init)\n",
    "    elif model_name=='ResNet18GTSRB':\n",
    "        training_model = ResNet18(class_n=class_n).to(device) #.apply(weights_init)\n",
    "    elif model_name=='MobileNetv2GTSRB':\n",
    "        training_model = mobilenet_v2(num_classes=class_n).to(device)\n",
    "    elif model_name=='EfficientNetGTSRB':\n",
    "        training_model = efficientnet_b0(num_classes=class_n).to(device) #.apply(weights_init)\n",
    "    elif model_name=='DenseNet121GTSRB':\n",
    "        training_model = densenet121(num_classes=class_n).to(device) #.apply(weights_init)\n",
    "    elif model_name=='ShuffleNetv2x1GTSRB':\n",
    "        training_model = shufflenet_v2_x1_0(num_classes=class_n).to(device) #.apply(weights_init)\n",
    "\n",
    "    print('Loading model done.')\n",
    "    training(training_model=training_model,\n",
    "             train_data=image_train,\n",
    "             train_labels=label_train,\n",
    "             test_data=image_test,\n",
    "             test_labels=label_test,\n",
    "             model_name=model_name,\n",
    "             device=device)\n",
    "\n",
    "def test_model(model_name):\n",
    "\n",
    "    if model_name=='TransformerGTSRB':\n",
    "        trained_model = Transformer(class_n=class_n).to(device)\n",
    "    elif model_name=='CNNsmallGTSRB':\n",
    "        trained_model = CNNsmall(class_n=class_n).to(device)\n",
    "    elif model_name=='CNNlargeGTSRB':\n",
    "        trained_model = CNNlarge(class_n=class_n).to(device)\n",
    "    elif model_name=='ResNet18GTSRB':\n",
    "        trained_model = ResNet18(class_n=class_n).to(device)\n",
    "    elif model_name=='MobileNetv2GTSRB':\n",
    "        trained_model = mobilenet_v2(num_classes=class_n).to(device)\n",
    "    elif model_name=='EfficientNetGTSRB':\n",
    "        trained_model = efficientnet_b0(num_classes=class_n).to(device)\n",
    "    elif model_name=='DenseNet121GTSRB':\n",
    "        trained_model = densenet121(num_classes=class_n).to(device)\n",
    "    elif model_name=='ShuffleNetv2x1GTSRB':\n",
    "        trained_model = shufflenet_v2_x1_0(num_classes=class_n).to(device)\n",
    "\n",
    "\n",
    "    trained_model.load_state_dict(\n",
    "        torch.load(f'models/{model_name}.pth',\n",
    "                   map_location=torch.device(device)))\n",
    "\n",
    "    with open('dataset/GTSRB/test.pkl', 'rb') as f:\n",
    "        test = pickle.load(f)\n",
    "        test_data, test_labels = test['data'], test['labels']\n",
    "\n",
    "    test_data = np.array([\n",
    "        pre_process_image(test_data[i]) for i in range(len(test_data))],\n",
    "        dtype=np.float32)\n",
    "\n",
    "    test_set = TrafficSignDataset(test_data, test_labels, device)\n",
    "    test_loader = DataLoader(test_set, batch_size=64, shuffle=False)\n",
    "\n",
    "    trained_model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_acc, _, inference_time = model_epoch(trained_model, test_loader)\n",
    "\n",
    "    # Calculate average inference time per sample\n",
    "    avg_inference_time = inference_time / len(test_set)\n",
    "\n",
    "    print(f'Test Acc: {round(float(test_acc / test_set.__len__()), 5)}')\n",
    "    print(f'Average Inference Time: {avg_inference_time * 1000.0:.5f} ms')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eEfLhk1bUc5I"
   },
   "source": [
    "##### **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6647265,
     "status": "ok",
     "timestamp": 1688903491917,
     "user": {
      "displayName": "Leopold Müller",
      "userId": "15867647540029964791"
     },
     "user_tz": -120
    },
    "id": "BENtXBXFUc5J",
    "outputId": "1f4ad202-22c2-452a-cfd5-65755385678f"
   },
   "outputs": [],
   "source": [
    "# train_model(model_name='CNNlargeGTSRB')\n",
    "# train_model(model_name='ShuffleNetv2x1GTSRB')\n",
    "# train_model(model_name='CNNsmallGTSRB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/fzi/ids/pavlitsk/.local/lib/python3.8/site-packages/torch/nn/functional.py:4255: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "/fzi/ids/pavlitsk/.local/lib/python3.8/site-packages/torch/nn/functional.py:4193: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.9943\n",
      "Average Inference Time: 0.01249 ms\n"
     ]
    }
   ],
   "source": [
    "test_model(model_name='TransformerGTSRB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.98124\n",
      "Average Inference Time: 0.00550 ms\n"
     ]
    }
   ],
   "source": [
    "test_model(model_name='CNNsmallGTSRB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.98907\n",
      "Average Inference Time: 0.01084 ms\n"
     ]
    }
   ],
   "source": [
    "test_model(model_name='CNNlargeGTSRB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.99177\n",
      "Average Inference Time: 0.02686 ms\n"
     ]
    }
   ],
   "source": [
    "test_model(model_name='ResNet18GTSRB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.98361\n",
      "Average Inference Time: 0.05126 ms\n"
     ]
    }
   ],
   "source": [
    "test_model(model_name='MobileNetv2GTSRB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.98725\n",
      "Average Inference Time: 0.08161 ms\n"
     ]
    }
   ],
   "source": [
    "test_model(model_name='EfficientNetGTSRB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1092,
     "status": "ok",
     "timestamp": 1688903493004,
     "user": {
      "displayName": "Leopold Müller",
      "userId": "15867647540029964791"
     },
     "user_tz": -120
    },
    "id": "6lkhRQJBUc5K",
    "outputId": "201bb55f-5d5b-44fc-ce2d-63903c996c6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.98092\n",
      "Average Inference Time: 0.15402 ms\n"
     ]
    }
   ],
   "source": [
    "test_model(model_name='DenseNet121GTSRB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.96057\n",
      "Average Inference Time: 0.06554 ms\n"
     ]
    }
   ],
   "source": [
    "test_model(model_name='ShuffleNetv2x1GTSRB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5288548\n"
     ]
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "model = efficientnet_b0(class_n=class_n)\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(pytorch_total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

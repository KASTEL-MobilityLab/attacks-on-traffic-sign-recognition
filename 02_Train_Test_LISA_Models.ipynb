{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o3pQsASCO2oj"
   },
   "source": [
    "### **Train and Test the Models on the LISA Dataset**\n",
    "\n",
    "Three models for traffic sign classification:\n",
    "1. CNNsmall (original LISA-CNN)\n",
    "2. CNNlarge (original GTSRB-CNN)\n",
    "3. CNN-STN \n",
    "\n",
    "Five generic image classification models\n",
    "1. ResNet18\n",
    "2. EfficientNet-B0\n",
    "3. DenseNet-121\n",
    "4. MobileNetv2\n",
    "5. ShuffleNetv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4781,
     "status": "ok",
     "timestamp": 1688977340224,
     "user": {
      "displayName": "Leopold M端ller",
      "userId": "15867647540029964791"
     },
     "user_tz": -120
    },
    "id": "bottzLq52uqB",
    "outputId": "14ba5933-6ad4-4eac-9c95-81fc11a68792"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: 5467 which is 80.00% of the total dataset\n",
      "Test data size: 1367 which is 20.00% of the total dataset\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('dataset/LISA/train.pkl', 'rb') as f:\n",
    "    train = pickle.load(f)\n",
    "    train_data, train_labels = train['data'], train['labels']\n",
    "with open('dataset/LISA/test.pkl', 'rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    test_data, test_labels = test['data'], test['labels']\n",
    "\n",
    "# Calculate the sizes in percentage\n",
    "total_size = len(train_data) + len(test_data)\n",
    "train_percentage = (len(train_data) / total_size) * 100\n",
    "test_percentage = (len(test_data) / total_size) * 100\n",
    "\n",
    "print(f\"Training data size: {len(train_data)} which is {train_percentage:.2f}% of the total dataset\")\n",
    "print(f\"Test data size: {len(test_data)} which is {test_percentage:.2f}% of the total dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import json\n",
    "from models import *\n",
    "from utils import *\n",
    "from torchvision.models import mobilenet_v2, efficientnet_b0, densenet121, shufflenet_v2_x1_0\n",
    "\n",
    "with open('classes.json', 'r') as config:\n",
    "    params = json.load(config)\n",
    "    class_n = params['LISA']['class_n']\n",
    "    device = params['device']\n",
    "    labels = params['GTSRB']['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 4987,
     "status": "ok",
     "timestamp": 1688990745438,
     "user": {
      "displayName": "Leopold M端ller",
      "userId": "15867647540029964791"
     },
     "user_tz": -120
    },
    "id": "u-cgXMSVO2o2"
   },
   "outputs": [],
   "source": [
    "def train_model(model_name, adv_train=False):\n",
    "\n",
    "    with open('dataset/LISA/train.pkl', 'rb') as f:\n",
    "        train = pickle.load(f)\n",
    "        train_data, train_labels = train['data'], train['labels']\n",
    "    with open('dataset/LISA/test.pkl', 'rb') as f:\n",
    "        test = pickle.load(f)\n",
    "        test_data, test_labels = test['data'], test['labels']\n",
    "\n",
    "    if model_name=='TransformerLISA':\n",
    "        training_model = Transformer(class_n=class_n).to(device).apply(weights_init)\n",
    "    elif model_name=='CNNsmallLISA':\n",
    "        training_model = CNNsmall(class_n=class_n).to(device).apply(weights_init)\n",
    "    elif model_name=='CNNlargeLISA':\n",
    "        training_model = CNNlarge(class_n=class_n).to(device).apply(weights_init)\n",
    "    elif model_name=='ResNet18LISA':\n",
    "        training_model = ResNet18(class_n=class_n).to(device) #.apply(weights_init)\n",
    "    elif model_name=='MobileNetv2LISA':\n",
    "        training_model = mobilenet_v2(num_classes=class_n).to(device) #.apply(weights_init)\n",
    "    elif model_name=='EfficientNetLISA':\n",
    "        training_model = efficientnet_b0(num_classes=class_n).to(device) #.apply(weights_init)\n",
    "    elif model_name=='DenseNet121LISA':\n",
    "        training_model = densenet121(num_classes=class_n).to(device) #.apply(weights_init)\n",
    "    elif model_name=='ShuffleNetv2x1LISA':\n",
    "        training_model = shufflenet_v2_x1_0(num_classes=class_n).to(device) #.apply(weights_init)\n",
    "\n",
    "\n",
    "    training(training_model=training_model,\n",
    "             train_data=train_data,\n",
    "             train_labels=train_labels,\n",
    "             test_data=test_data,\n",
    "             test_labels=test_labels,\n",
    "             model_name=model_name,\n",
    "             device=device)\n",
    "\n",
    "\n",
    "def test_model(model_name):\n",
    "\n",
    "    if model_name=='TransformerLISA':\n",
    "        trained_model = Transformer(class_n=class_n).to(device)\n",
    "    elif model_name=='CNNsmallLISA':\n",
    "        trained_model = CNNsmall(class_n=class_n).to(device)\n",
    "    elif model_name=='CNNlargeLISA':\n",
    "        trained_model = CNNlarge(class_n=class_n).to(device)\n",
    "    elif model_name=='ResNet18LISA':\n",
    "        trained_model = ResNet18(class_n=class_n).to(device)\n",
    "    elif model_name=='MobileNetv2LISA':\n",
    "        trained_model = mobilenet_v2(num_classes=class_n).to(device)\n",
    "    elif model_name=='EfficientNetLISA':\n",
    "        trained_model = efficientnet_b0(num_classes=class_n).to(device)\n",
    "    elif model_name=='DenseNet121LISA':\n",
    "        trained_model = densenet121(num_classes=class_n).to(device)\n",
    "    elif model_name=='ShuffleNetv2x1LISA':\n",
    "        trained_model = shufflenet_v2_x1_0(num_classes=class_n).to(device)\n",
    "\n",
    "    trained_model.load_state_dict(\n",
    "        torch.load(f'models/{model_name}.pth',\n",
    "                   map_location=torch.device(device)))\n",
    "\n",
    "    with open('dataset/LISA/test.pkl', 'rb') as f:\n",
    "        test = pickle.load(f)\n",
    "        test_data, test_labels = test['data'], test['labels']\n",
    "\n",
    "    test_set = TrafficSignDataset(test_data, test_labels, device)\n",
    "    test_loader = DataLoader(test_set, batch_size=64, shuffle=False)\n",
    "\n",
    "    trained_model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_acc, _, inference_time = model_epoch(trained_model, test_loader)\n",
    "\n",
    "    # Calculate average inference time per sample\n",
    "    avg_inference_time = inference_time / len(test_set)\n",
    "\n",
    "    print(f'Test Acc: {round(float(test_acc / test_set.__len__()), 4)}')\n",
    "    print(f'Average Inference Time: {avg_inference_time * 1000.0:.5f} ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Js-ciACO2pH"
   },
   "source": [
    "##### **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 221113,
     "status": "ok",
     "timestamp": 1688766286480,
     "user": {
      "displayName": "Leopold M端ller",
      "userId": "15867647540029964791"
     },
     "user_tz": -120
    },
    "id": "4BHpfpTNO2pI",
    "outputId": "c52dbf91-9e87-46a0-9391-324f9bf051a9"
   },
   "outputs": [],
   "source": [
    "# train_model(model_name='DenseNet121LISA')\n",
    "# train_model(model_name='ShuffleNetv2x1LISA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ec62ccVbO2pN"
   },
   "source": [
    "##### Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 306,
     "status": "ok",
     "timestamp": 1688990763497,
     "user": {
      "displayName": "Leopold M端ller",
      "userId": "15867647540029964791"
     },
     "user_tz": -120
    },
    "id": "jI3lGLxHO2pO",
    "outputId": "5ef76e86-1793-4f5e-d474-b2ad658c6635"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.9985\n",
      "Average Inference Time: 0.01426 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/fzi/ids/pavlitsk/.local/lib/python3.8/site-packages/torch/nn/functional.py:4255: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "/fzi/ids/pavlitsk/.local/lib/python3.8/site-packages/torch/nn/functional.py:4193: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "test_model(model_name='TransformerLISA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.9971\n",
      "Average Inference Time: 0.00705 ms\n"
     ]
    }
   ],
   "source": [
    "test_model(model_name='CNNsmallLISA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.9978\n",
      "Average Inference Time: 0.01114 ms\n"
     ]
    }
   ],
   "source": [
    "test_model(model_name='CNNlargeLISA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.9985\n",
      "Average Inference Time: 0.02994 ms\n"
     ]
    }
   ],
   "source": [
    "test_model(model_name='ResNet18LISA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.9971\n",
      "Average Inference Time: 0.05163 ms\n"
     ]
    }
   ],
   "source": [
    "test_model(model_name='MobileNetv2LISA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.9934\n",
      "Average Inference Time: 0.09199 ms\n"
     ]
    }
   ],
   "source": [
    "test_model(model_name='EfficientNetLISA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.9963\n",
      "Average Inference Time: 0.19866 ms\n"
     ]
    }
   ],
   "source": [
    "test_model(model_name='DenseNet121LISA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.9927\n",
      "Average Inference Time: 0.09243 ms\n"
     ]
    }
   ],
   "source": [
    "test_model(model_name='ShuffleNetv2x1LISA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2278604\n"
     ]
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "model = shufflenet_v2_x1_0(class_n).to(device)\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(pytorch_total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
